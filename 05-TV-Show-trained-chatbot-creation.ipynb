{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cabad95d",
   "metadata": {},
   "source": [
    "# **05-TV-Show-trained-chatbot-creation**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee832dd",
   "metadata": {},
   "source": [
    "# ``Main Goals of Cleaning``\n",
    "\n",
    "- **Remove noise**: timestamps, speaker labels (if any), scene directions.\n",
    "\n",
    "- **Structure the data**: into question-response (or speaker1-speaker2) pairs if building a chatbot.\n",
    "\n",
    "- **Preprocess text**: lowercase, punctuation cleanup, lemmatization, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0540f928",
   "metadata": {},
   "source": [
    "\n",
    "## Step-by-Step Process\n",
    "\n",
    "The step-by-step from raw subtitle text to a cleaned conversational dataset and finally a chatbot model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f847a737",
   "metadata": {},
   "source": [
    "# **Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e2cfd61e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "import string\n",
    "import pandas as pd\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "import re\n",
    "import nltk\n",
    "import pandas as pd\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "84562acf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\rurig\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\rurig\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\rurig\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\rurig\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One-time downloads (run once)\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab023031",
   "metadata": {},
   "source": [
    "# Step 1: Read and Inspect the SRT File\n",
    "\n",
    "The SRP typically looks like this:\n",
    "\n",
    "```python \n",
    "1\n",
    "00:00:01,000 --> 00:00:03,000\n",
    "Hello, how are you?\n",
    "\n",
    "2\n",
    "00:00:03,500 --> 00:00:05,000\n",
    "I'm fine, thanks.\n",
    "```\n",
    "\n",
    "upon inspecting the srt (SubRip Subtitle) we need to extract just the dialogue lines, removing timestamps and sequence numbers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d63e6e0",
   "metadata": {},
   "source": [
    "# Step 2: Clean the SRT File\n",
    "\n",
    "We'll clean the file by:\n",
    "\n",
    "- Removing subtitle sequence numbers\n",
    "\n",
    "- Removing timestamps\n",
    "\n",
    "- Keeping only actual spoken lines\n",
    "\n",
    "- Removing empty lines or noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c06d8bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.1 Cleaning the SRT\n",
    "\n",
    "# Read the SRT file\n",
    "with open(\"data/suits-1x01-pilot.en.srt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "cleaned_lines = []\n",
    "for line in lines:\n",
    "    # Skip sequence numbers\n",
    "    if re.match(r\"^\\d+\\s*$\", line):\n",
    "        continue\n",
    "    # Skip timestamps\n",
    "    if re.match(r\"^\\d{2}:\\d{2}:\\d{2},\\d{3}\", line):\n",
    "        continue\n",
    "    # Skip empty lines\n",
    "    if line.strip() == \"\":\n",
    "        continue\n",
    "    # Keep actual spoken line\n",
    "    cleaned_lines.append(line.strip())\n",
    "\n",
    "# Join into clean dialogue\n",
    "cleaned_text = \"\\n\".join(cleaned_lines)\n",
    "\n",
    "# Save the cleaned result to a new text file\n",
    "with open(\"data/05-cleaned-suits-pilot.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(cleaned_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7345afcd",
   "metadata": {},
   "source": [
    "# Step 3: Structure the data into Pairs for Chatbot\n",
    "\n",
    "Converting the dialogue into prompt-response pairs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee6cd420",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('\\ufeff1', '[Muffled chatter]'),\n",
       " ('[Muffled chatter]', '[Knocking]'),\n",
       " ('[Knocking]', \"Gerald Tate's here.\"),\n",
       " (\"Gerald Tate's here.\", 'He wants to know'),\n",
       " ('He wants to know', \"what's happening to his deal.\"),\n",
       " (\"what's happening to his deal.\", 'Go get Harvey.'),\n",
       " ('Go get Harvey.',\n",
       "  '== sync, corrected by <font color=\"#00ff00\">elderman</font> =='),\n",
       " ('== sync, corrected by <font color=\"#00ff00\">elderman</font> ==',\n",
       "  'I check.'),\n",
       " ('I check.', 'Raise.'),\n",
       " ('Raise.', '5,000.')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create prompt-response pairs\n",
    "pairs = []\n",
    "\n",
    "for i in range(len(cleaned_lines) - 1):\n",
    "    input_text = cleaned_lines[i]\n",
    "    target_text = cleaned_lines[i + 1]\n",
    "    pairs.append((input_text, target_text))\n",
    "\n",
    "# printing the first set 10 entries in the `pairs` LIST\n",
    "pairs[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d20c8d2b",
   "metadata": {},
   "source": [
    "### Optional - Save these pairs into a CSV for training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aca9ba4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(pairs, columns=[\"input\", \"response\"])\n",
    "df.to_csv(r\"data\\05-chatbot-pairs-data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "443a0bf6",
   "metadata": {},
   "source": [
    "# Step 4: Preprocess Text for Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e9524e3",
   "metadata": {},
   "source": [
    "You may want to:\n",
    "\n",
    "- Lowercase everything\n",
    "\n",
    "- Remove punctuation\n",
    "\n",
    "- Tokenize (optional)\n",
    "\n",
    "- Lemmatize or stem (optional for traditional models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d293f9e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic Fucntion\n",
    "def preprocess(text):\n",
    "    text = text.lower()\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    return text\n",
    "\n",
    "df['input'] = df['input'].apply(preprocess)\n",
    "df['response'] = df['response'].apply(preprocess)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e6386df",
   "metadata": {},
   "source": [
    "Here is a more complete preprocess() function that addresses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3077b5e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    # Lowercase everything\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove HTML-like tags and entities\n",
    "    text = re.sub(r'<.*?>', '', text)           # Remove HTML tags like <i>, </b>\n",
    "    text = re.sub(r'&[a-z]+;', ' ', text)       # Replace HTML entities like &nbsp;\n",
    "    \n",
    "    # Normalize punctuation spacing\n",
    "    text = re.sub(r'[\\.\\?!,;:]+', '.', text)    # Replace runs of punctuation with a period\n",
    "    text = re.sub(r'\\.{2,}', '.', text)         # Replace multiple dots with one\n",
    "    text = re.sub(r'[^a-z0-9\\s\\']', '', text)   # Remove all remaining punctuation except apostrophes\n",
    "\n",
    "    # Replace multiple spaces/newlines/tabs with a single space\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    \n",
    "    # Trim leading/trailing whitespace\n",
    "    text = text.strip()\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f5acea",
   "metadata": {},
   "source": [
    "Applying this fucntion to the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4d555c6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>muffled chatter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>muffled chatter</td>\n",
       "      <td>knocking</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>knocking</td>\n",
       "      <td>gerald tates here</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gerald tates here</td>\n",
       "      <td>he wants to know</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>he wants to know</td>\n",
       "      <td>whats happening to his deal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               input                     response\n",
       "0                  1              muffled chatter\n",
       "1    muffled chatter                     knocking\n",
       "2           knocking            gerald tates here\n",
       "3  gerald tates here             he wants to know\n",
       "4   he wants to know  whats happening to his deal"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['input'] = df['input'].apply(preprocess)\n",
    "df['response'] = df['response'].apply(preprocess)\n",
    "\n",
    "# Checking the frst 10 input\n",
    "pd.concat([df['input'], df['response']], axis = 1).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd75b25b",
   "metadata": {},
   "source": [
    "Let's enhance the preprocessing function to include:\n",
    "\n",
    "- 1. **Lemmatization** – Reduce words to their base (e.g., \"running\" → \"run\")\n",
    "\n",
    "- 2. **Stopword removal** – Remove common non-informative words (like \"the\", \"is\", \"and\")\n",
    "\n",
    "Updated `preprocess()` with NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "75db4815",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def preprocess(text):\n",
    "    # Lowercase\n",
    "    text = text.lower()\n",
    "\n",
    "    # Remove HTML tags and entities\n",
    "    text = re.sub(r'<.*?>', '', text)\n",
    "    text = re.sub(r'&[a-z]+;', ' ', text)\n",
    "\n",
    "    # Replace punctuation with space\n",
    "    text = re.sub(r'[^a-z0-9\\s\\']', ' ', text)\n",
    "\n",
    "    # Normalize whitespace\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "\n",
    "    # Tokenize\n",
    "    tokens = word_tokenize(text)\n",
    "\n",
    "    # Remove stopwords and lemmatize\n",
    "    cleaned = [lemmatizer.lemmatize(word) for word in tokens if word not in stop_words]\n",
    "\n",
    "    return ' '.join(cleaned)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de0b4ef",
   "metadata": {},
   "source": [
    "Applying this new function to the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f642d3be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>muffled chatter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>muffled chatter</td>\n",
       "      <td>knocking</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>knocking</td>\n",
       "      <td>gerald tate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gerald tate</td>\n",
       "      <td>want know</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>want know</td>\n",
       "      <td>whats happening deal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>whats happening deal</td>\n",
       "      <td>go get harvey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>go get harvey</td>\n",
       "      <td>sync corrected font color00ff00eldermanfont</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>sync corrected font color00ff00eldermanfont</td>\n",
       "      <td>check</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>check</td>\n",
       "      <td>raise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>raise</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         input  \\\n",
       "0                                            1   \n",
       "1                              muffled chatter   \n",
       "2                                     knocking   \n",
       "3                                  gerald tate   \n",
       "4                                    want know   \n",
       "5                         whats happening deal   \n",
       "6                                go get harvey   \n",
       "7  sync corrected font color00ff00eldermanfont   \n",
       "8                                        check   \n",
       "9                                        raise   \n",
       "\n",
       "                                      response  \n",
       "0                              muffled chatter  \n",
       "1                                     knocking  \n",
       "2                                  gerald tate  \n",
       "3                                    want know  \n",
       "4                         whats happening deal  \n",
       "5                                go get harvey  \n",
       "6  sync corrected font color00ff00eldermanfont  \n",
       "7                                        check  \n",
       "8                                        raise  \n",
       "9                                         5000  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['input'] = df['input'].apply(preprocess)\n",
    "df['response'] = df['response'].apply(preprocess)\n",
    "\n",
    "# Checking the frst 10 input\n",
    "pd.concat([df['input'], df['response']], axis = 1).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab8d03da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
